{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2076ec",
   "metadata": {},
   "source": [
    "# Part II B - CF969-7-SP-CO\n",
    "## Big Data for Computational Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e04fc9",
   "metadata": {},
   "source": [
    "### a linear regression approach with Ridge (or L1) and Lasso (or L2) regularisation to predict whether a firm is in an investment grade or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317c0f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Ridge accuracy: 26.176470588235297\n",
      "Percentage Lasso accuracy: 25.588235294117645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Loading the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('MLF_GP1_CreditScore.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "# Features are the independent variables that we will use to predict the target variable.\n",
    "features = df.drop(['InvGrd', 'Rating'], axis=1)\n",
    "target = df['Rating']\n",
    "\n",
    "# Encode target variable\n",
    "# This is necessary because the target variable is a categorical variable.\n",
    "le = LabelEncoder()\n",
    "target_encoded = le.fit_transform(target)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "# This is done so that we can train the model on the training set and then evaluate the model on the test set.\n",
    "# The test set is used to measure the accuracy of the model on unseen data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "# This is done to normalize the features so that they are on a similar scale.\n",
    "# This is important for the linear regression model to work properly.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit a linear regression model with Ridge regularization\n",
    "# Ridge regularization is a technique that helps to prevent overfitting.\n",
    "# Overfitting is a problem that occurs when the model learns the training data too well and is not able to generalize to new data.\n",
    "ridge = Ridge(alpha=8.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict target variable for test set and convert to categories\n",
    "# We need to convert this to a binary classification.\n",
    "y_pred_ridge = le.inverse_transform(np.round(ridge.predict(X_test)).astype(int))\n",
    "y_test = le.inverse_transform(y_test)\n",
    "\n",
    "# Generate binary classification list for predicted and actual target variable\n",
    "Good = ['Aaa', 'Aa1', 'Aa2', 'Aa3', 'A1', 'A2', 'A3', 'Baa1', 'Baa2', 'Baa3']\n",
    "y_pred_ridge_grade = list(map(lambda x: 1 if x in Good else 0, y_pred_ridge))\n",
    "y_test_grade = list(map(lambda x: 1 if x in Good else 0, y_test))\n",
    "\n",
    "# Fit a linear regression model with Lasso regularization\n",
    "lasso = Lasso(alpha=0.02)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict target variable for test set and convert to categories\n",
    "y_pred_lasso = le.inverse_transform(np.round(lasso.predict(X_test)).astype(int))\n",
    "\n",
    "# Generate binary classification list for predicted target variable\n",
    "y_pred_lasso_grade = list(map(lambda x: 1 if x in Good else 0, y_pred_lasso))\n",
    "\n",
    "# Evaluate the performance of the models on the test data\n",
    "# The accuracy score is a measure of how well the model predicts the target variable.\n",
    "accuracy_ridge = accuracy_score(y_test_grade, y_pred_ridge_grade)\n",
    "accuracy_lasso = accuracy_score(y_test_grade, y_pred_lasso_grade)\n",
    "\n",
    "# Print the accuracies\n",
    "print('Percentage Ridge accuracy:', 100*accuracy_ridge)\n",
    "print('Percentage Lasso accuracy:', 100*accuracy_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1a441d",
   "metadata": {},
   "source": [
    "### a logistic regression approach with Ridge (or L1) and Lasso (or L2) regularisation to predict whether a firm is in an investment grade or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b984c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Ridge accuracy: 80.58823529411765\n",
      "Percentage Lasso accuracy: 80.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the credit score dataset into a pandas DataFrame\n",
    "credit_df = pd.read_csv('MLF_GP1_CreditScore.csv')\n",
    "\n",
    "# Drop the 'InvGrd' and 'Rating' columns from the input features\n",
    "X = credit_df.drop(['InvGrd', 'Rating'], axis=1)\n",
    "\n",
    "# Encode the target variable 'Rating' using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(credit_df['Rating'])\n",
    "\n",
    "# Split the dataset into training and test sets with 80-20 split ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# Scale the input features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit a logistic regression model with Ridge regularization to the training data\n",
    "ridge = LogisticRegression(penalty='l1', solver='saga', max_iter=10000, C=0.1, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the trained Ridge logistic regression model\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Inverse transform the predicted and actual target variables from encoded to original values\n",
    "y_pred_ridge = le.inverse_transform(y_pred_ridge)\n",
    "y_test = le.inverse_transform(y_test)\n",
    "\n",
    "# Map the target variable values to binary values (1 for investment grade and 0 for non-investment grade)\n",
    "yes_labels = ['Aaa', 'Aa1', 'Aa2', 'Aa3', 'A1', 'A2', 'A3', 'Baa1', 'Baa2', 'Baa3']\n",
    "y_pred_ridge_grade = list(map(lambda x: 1 if x in yes_labels else 0, y_pred_ridge))\n",
    "y_test_grade = list(map(lambda x: 1 if x in yes_labels else 0, y_test))\n",
    "\n",
    "# Fit a logistic regression model with Lasso regularization to the training data\n",
    "lasso = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=10000, C=1.0, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the trained Lasso logistic regression model\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Inverse transform the predicted target variables from encoded to original values\n",
    "y_pred_lasso = le.inverse_transform(y_pred_lasso)\n",
    "\n",
    "# Map the target variable values to binary values (1 for investment grade and 0 for non-investment grade)\n",
    "y_pred_lasso_grade = list(map(lambda x: 1 if x in yes_labels else 0, y_pred_lasso))\n",
    "\n",
    "# Evaluate the performance of the models on the test data using accuracy score metric\n",
    "accuracy_ridge = accuracy_score(y_test_grade, y_pred_ridge_grade)\n",
    "accuracy_lasso = accuracy_score(y_test_grade, y_pred_lasso_grade)\n",
    "\n",
    "# Print the accuracies\n",
    "print('Percentage Ridge accuracy:', 100*accuracy_ridge)\n",
    "print('Percentage Lasso accuracy:', 100*accuracy_lasso)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b0a7c",
   "metadata": {},
   "source": [
    "### A Neural Networks based approach to classify the firmâ€™s rating into one of the rating categories and predict if it is in an investment grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ad846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('MLF_GP1_CreditScore.csv')\n",
    "\n",
    "# Encode the rating column as categorical labels\n",
    "le = LabelEncoder()\n",
    "df['Rating_Encoded'] = le.fit_transform(df['Rating'])\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X = df.drop(['InvGrd', 'Rating_Encoded','Rating'], axis=1)\n",
    "y_rating = df['Rating_Encoded']\n",
    "y_investment_grade = df['InvGrd']\n",
    "X_train, X_test, y_train_rating, y_test_rating, y_train_grade, y_test_grade = train_test_split(X, y_rating, y_investment_grade, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define a neural network model for the rating classification task\n",
    "model_rating = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "model_rating.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model_rating.fit(X_train, y_train_rating, validation_data=(X_test, y_test_rating), epochs=50, batch_size=32)\n",
    "\n",
    "# Predict the ratings for the test data\n",
    "y_pred_rating = model_rating.predict(X_test)\n",
    "print(y_pred_rating)\n",
    "\n",
    "y_pred_rating = le.inverse_transform(y_pred_rating.argmax(axis=1))\n",
    "y_test_rating = le.inverse_transform(y_test_rating)\n",
    "\n",
    "#print(y_pred_rating)\n",
    "\n",
    "yes=['Aaa', 'Aa1', 'Aa2', 'Aa3', 'A1', 'A2', 'A3', 'Baa1', 'Baa2', 'Baa3']\n",
    "y_pred_rating = list(map(lambda x: 1 if x in yes else 0, y_pred_rating))\n",
    "y_test_rating = list(map(lambda x: 1 if x in yes else 0, y_test_rating))\n",
    "\n",
    "#y_pred_rating = y_pred_rating.map(lambda x: 1 if x in yes else 0)\n",
    "#y_test_rating = y_test_rating.map(lambda x: 1 if x in yes else 0)\n",
    "\n",
    "# Define a neural network model for the investment grade classification task\n",
    "model_grade = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and Adam optimizer\n",
    "model_grade.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on the training data\n",
    "model_grade.fit(X_train, y_train_grade, validation_data=(X_test, y_test_grade), epochs=50, batch_size=32)\n",
    "\n",
    "# Predict the investment grade for the test data\n",
    "y_pred_grade = model_grade.predict(X_test)\n",
    "y_pred_grade = (y_pred_grade > 0.5).astype(int)\n",
    "\n",
    "y_pred_rating=np.array(y_pred_rating)\n",
    "y_test_rating=np.array(y_test_rating)\n",
    "\n",
    "# Evaluate the performance of the models on the test data\n",
    "accuracy_for_rating = accuracy_score(y_test_rating, y_pred_rating)\n",
    "accuracy_for_grade = accuracy_score(y_test_grade, y_pred_grade)\n",
    "\n",
    "\n",
    "print('percentage Rating accuracy:', accuracy_for_rating)\n",
    "print(\" I also calculated model accuracy when we take y as grade\")\n",
    "print('percentage Grade accuracy:', accuracy_for_grade)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
